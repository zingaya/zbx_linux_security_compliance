#!/usr/bin/env python3
# Constants for file paths and Zabbix configuration. Can be overridden via arguments
INVENTORY_PATH = '/etc/ansible/hosts' # Ignored if ZABBIX_API and API_TOKEN are defined
ZABBIX_SERVER = ['127.0.0.1:10051'] # Zabbix sender will try to connect any of the nodes
ZABBIX_HOST = 'myjumpserver' # Zabbix host where logs from this script will be sent
USER_LOGIN = 'root'

# Zabbix server URL and API token (optional)
# If True, will generate a temporal inventory file from Zabbix database, using hostname and groupname
#ZABBIX_API = 'http://zabbix.local/zabbix/api_jsonrpc.php'
#API_TOKEN = 'apitoken12345'

# Change default for Ansible forks and ssh timeout (optional)
#ANSIBLE_FORKS = 5
#ANSIBLE_TIMEOUT = 10

# SSH Key path (default: '~/.ssh/id_rsa')
SSH_KEY = '~/.ssh/id_rsa'

# Allowed package manager. Add/remove entries as needed
PKG_MGR = ["yum", "apt", "dnf"] # Can be overridden via arguments

# Temporary directory and template path
TMP_DIR = "/tmp/sec_updates"

##### Do not edit from here #####
import ansible_runner
import argparse
import os
import re
import json
import yaml
import sys
import shutil
import time
import requests
import concurrent.futures
from pathlib import Path
from zabbix_utils import ItemValue, Sender
from collections import defaultdict

# Read all JSON result files generated by Ansible
def process_json_files(directory, items, combined_output, host_list):
    try:
        directory_path = Path(directory)
        files = [f for f in directory_path.glob("*.json")]
    except OSError as e:
        combined_output += f"Error accessing directory {directory}: {e}\n"
        return

    for filename in files:
        path = os.path.join(directory, filename)
        try:
            with open(path, 'r') as f:
                data = json.load(f)
        except json.JSONDecodeError as e:
            combined_output += f"Error reading JSON from {path}: {e}\n"
            continue

        hostname = data.get("hostname", "unknown")
        if 'agent.hostname' in hostname:
            m = re.search(r'\[s\|(.*)\]', hostname)
            if m:
                hostname = m.group(1)

        # Merge host info from JSON file and the facts from host_list
        host_info = host_list.get(data["inventory_hostname"], {})
        data.update(host_info)  # Use update for merging dictionaries
        
        # Remove fields that are not needed anymore
        data.pop("inventory_hostname", None)
        data.pop("hostname", None)

        items.append(ItemValue(hostname, "report.raw", json.dumps([data])))

def build_playbook(args, packages_split_lock, packages_split_unlock, package_mgr):
    # Start playbook
    play = {
        "name": "Linux updates management (" + package_mgr + ")",
        "hosts": "all",
        "gather_facts": False,
        "become": args.become,
        "vars": {
            "packages_to_lock": packages_split_lock,
            "packages_to_unlock": packages_split_unlock,
            "updates": ""
        },
        "tasks": []
    }

    # Add tasks as needed
    tasks = play["tasks"]
 
    # Always check YUM version lock is installed
    if package_mgr in ("yum", "dnf"):
        tasks += [
            {
                "name": "Ensure yum-plugin-versionlock",
                "yum": {"name": "yum-plugin-versionlock", "state": "present"}
            }
        ]

    # Only if lock/unlock packages found
    if args.unlock_packages:
        if package_mgr in ("yum", "dnf"):
            tasks += [
                {
                    "name": "Unlock packages (YUM)",
                    "community.general.yum_versionlock": {"name": "{{ item }}", "state": "absent"},
                    "loop": "{{ packages_to_unlock }}",
                    "register": "unlock_result"
                }
            ]
        if package_mgr in ("apt"):
            tasks += [
                {
                    "name": "Unlock packages (APT)",
                    "command": "apt-mark unhold {{ item }}",
                    "loop": "{{ packages_to_unlock }}",
                    "register": "unlock_result"
                }
            ]
    if args.lock_packages:
        if package_mgr in ("yum", "dnf"):
            tasks += [
                {
                    "name": "Lock packages (YUM)",
                    "community.general.yum_versionlock": {"name": "{{ item }}", "state": "present"},
                    "loop": "{{ packages_to_lock }}",
                    "register": "lock_result"
                }
            ]
        if package_mgr in ("apt"):
            tasks += [
                {
                    "name": "Lock packages (APT)",
                    "command": "apt-mark hold {{ item }}",
                    "loop": "{{ packages_to_lock }}",
                    "register": "lock_result"
                }
            ]


    # Always get locked packages
    if package_mgr in ("yum", "dnf"):
        tasks += [
            {
                "name": "Get locked (YUM)",
                "shell": "yum versionlock",
                "register": "lock_packages"
            },
            {
                "name": "Parse YUM locked",
                "set_fact": {
                    "locked": "{{ lock_packages.stdout_lines | select('match', '^(0:([^0-9-]+)|^([^:]+)-0:).*') | map('regex_replace', '^(0:([^0-9-]+)|^([^:]+)-0:).*', '{\"name\": \"\\2\\3\"}') | map('from_json') | list | unique }}"
                }
            }
        ]
    if package_mgr in ("apt"):
        tasks += [
            {
                "name": "Get locked (APT)",
                "shell": "apt-mark showhold",
                "register": "lock_packages"
            },
            {
                "name": "Parse APT locked",
                "set_fact": {
                    "locked": "{{ lock_packages.stdout_lines | map('regex_replace', '^(.*)$', '{\"name\": \"\\1\"}') | map('from_json') | list }}"
                }
            }
        ]
            
    # Only if argument --upgrade
    if args.upgrade == "yes":
        if package_mgr in ("yum", "dnf"):
            tasks += [
                {
                    "name": "Upgrade YUM",
                    "yum": {"name": "*", "state": "latest"},
                    "register": "upgrade_result"
                }
            ]
        if package_mgr in ("apt"):
            tasks += [
                {
                    "name": "Upgrade APT",
                    "apt": {"update_cache": True, "upgrade": "yes"},
                    "register": "upgrade_result"
                }
            ]

    # Always check for updates
    if package_mgr in ("yum", "dnf"):
        tasks += [
            {
                "name": "Check YUM updates",
                "yum": {"list": "updates"},
                "register": "yum_updates"
            },
            {
                "name": "Parse YUM updates",
                "set_fact": {
                    "updates": "{{ yum_updates.results | list }}"
                }
            }
        ]
    if package_mgr in ("apt"):
        tasks += [
            {
                "name": "Check APT updates",
                "shell": "apt list --upgradeable | grep -E '^[a-zA-Z0-9.-]+/' | awk -F/ '{print $1}'",
                "register": "apt_updates"
            },
            {
                "name": "Parse APT updates",
                "set_fact": {
                    "updates": "{{ apt_updates.stdout_lines | map('regex_replace', '^(.*)$', '{ \"name\": \"\\1\" }') | map('from_json') | list }}"
                }
            }
        ]

    # Always write final JSON report to disk
    tasks += [
        {
            "name": "Get hostname",
            "shell": "(zabbix_agent2 -t agent.hostname || zabbix_agent -t agent.hostname || zabbix_agentd -t agent.hostname) 2>/dev/null | grep hostname || cat /etc/hostname",
            "register": "cmd_output"
        },
        {
            "name": "Prepare filename and write updates",
            "block": [
                {
                    "set_fact": {
                        "hostname": "{{ cmd_output.stdout }}",
                        "filename": "{{ cmd_output.stdout | regex_replace('.*\\|(.+?)\\]', '\\1') }}.json"
                    }
                },
                {
                    "lineinfile": {
                        "path": TMP_DIR + "/{{ filename }}",
                        "line": "{{ {'hostname': hostname, 'inventory_hostname': inventory_hostname, 'current_date': now(utc=true), 'updates': updates, 'locked_packages': locked | default([])} | to_json }}",
                        "create": True,
                        "mode": "0644"
                    },
                    "delegate_to": "localhost"
                }
            ]
        }
    ]
    
    # Finally, transform JSON to YAML playbook and write the file
    with open(f"{TMP_DIR}/{package_mgr}_playbook.yaml", "w") as f:
        yaml.dump([play], f, indent=2, sort_keys=False, default_flow_style=False)

    printverbose(f"Template created {TMP_DIR}/{package_mgr}_playbook.yaml")

# Print if verbose is true
def printverbose(string):
    if verbose:
        print(string)

# List Zabbix hosts
def get_zabbix_hosts():
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {API_TOKEN}'
    }
    data = {
        "jsonrpc": "2.0",
        "method": "template.get",
        "params": {
            "output": ["templateid"],
            "selectHostGroups": "extend",
            "selectInterfaces": "extend",
            "selectParentTemplates": "extend",
            "filter": {"host": "Linux - Security and compliance"}
        },
        "id": 1
    }
    try:
        post_response = requests.post(ZABBIX_API, data=json.dumps(data), headers=headers)
        templateid = post_response.json().get('result', [])
        printverbose("Template ID: " + templateid[0].get('templateid'))
    except Exception as e:
        return f"Error: {e}"   
    
    data = {
        "jsonrpc": "2.0",
        "method": "host.get",
        "params": {
            "output": ["hostid", "name", "groupids", "status"],
            "selectHostGroups": "extend",
            "selectInterfaces": "extend",
            "status": 0,
            "templateids": templateid[0].get('templateid')
        },
        "id": 1
    }
    try:
        post_response = requests.post(ZABBIX_API, data=json.dumps(data), headers=headers)
        hosts = post_response.json().get('result', [])
        return hosts
    except Exception as e:
        return f"Error: {e}"

# Process JSON API
def process_json_host(hosts):
    selected_interface = None

    for interface in hosts.get('interfaces', []):
        if (interface['useip'] == '1' and interface['ip'] != '127.0.0.1') or interface['useip'] == '0':
            selected_interface = interface
            break

    if selected_interface:
        # We need to replace spaces with underscores, so it can be used in YAML
        hostname = hosts['name'].replace(" ", "_")
        ansible_host = selected_interface['ip'] if selected_interface['useip'] == '1' else selected_interface['dns']
        hostgroups = [group['name'].replace(" ", "_").replace("/", "_") for group in hosts.get('hostgroups', [])]
        return hostname, ansible_host, hostgroups
    return None

# Create the Ansible inventory YAML file
def create_ansible_inventory(PATH):
    inventory = {'all': {'hosts': {}}}

    # Get the list of hosts
    hosts = get_zabbix_hosts()
    if "Error: " in hosts:
        return hosts
    
    printverbose("Zabbix API response: " + json.dumps(hosts))

    # Multithread JSON data processing    
    # Get the number of CPUs and set max_workers to half
    cpu_count = os.cpu_count()
    max_workers = max(1, cpu_count // 2)  # Half of the CPUs
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = executor.map(process_json_host, hosts)
    
    for result in results:
        if result: # Omit result with no valid interfaces        
            hostname, ansible_host, hostgroups = result
            
            # Add host to inventory with groups
            inventory['all']['hosts'][hostname] = {'ansible_host': ansible_host}
            
            # Add hostgroups to inventory
            for group in hostgroups:
                if group not in inventory:
                    inventory[group] = {'hosts': {}}
                inventory[group]['hosts'][hostname] = {'ansible_host': ansible_host}

    with open(PATH, 'w') as f:
        yaml.dump(inventory, f, default_flow_style=False)

    print(f"Ansible {PATH} file created successfully!")
    
# Validation   
def valid_hostport_list(lst):
    if not isinstance(lst, list):
        return False
    for entry in lst:
        if not isinstance(entry, str) or not entry.strip():
            return False
        parts = entry.split(':')
        host = parts[0]
        port = parts[1] if len(parts) == 2 else None

        # Validate hostname/IP
        try:
            socket.getaddrinfo(host, None)
        except socket.gaierror:
            return False

        # Validate port if present
        if port:
            if not port.isdigit() or not (1 <= int(port) <= 65535):
                return False
    return True
    
# Validate positive integer
def is_positive_int(val):
    try:
        return int(val) > 0
    except (ValueError, TypeError):
        return False

# Validate Hostname/IP/FQDN/URL
def is_valid_host(host):
    pattern = re.compile(
        r"^([a-zA-Z0-9\-\.]+|\d{1,3}(\.\d{1,3}){3})(:\d{1,5})?$"
    )
    return bool(pattern.match(host))
    
def is_valid_url(url):
    pattern = re.compile(
        r"^https?://"
        r"[a-zA-Z0-9\-\.]+"
        r"(:\d+)?"
        r"(/.*)?$"
    )
    return bool(pattern.match(url))

def main():
    print("Initializing...")    
    start = time.time()

    global TMP_DIR  # Declare it as global to modify it
    # Remove trailing '/' if any
    TMP_DIR = TMP_DIR.rstrip('/')
    if not (isinstance(TMP_DIR, str) and TMP_DIR.strip() != ""): raise Exception("TMP_DIR must be a non-empty/non-root path string")
    
    # Check if another instance of this script is already running
    if os.path.exists(f"{TMP_DIR}/.lock"):
        print("Error: Script already running, or " + f"{TMP_DIR}/.lock" + " must be deleted manually.")
        print("Exiting")
        sys.exit(0)
    else:
        # Prepare temp dir and lock
        try:
            shutil.rmtree(TMP_DIR)
        except FileNotFoundError:
            pass
            
        try:
            os.mkdir(TMP_DIR)
            lock = os.open(f"{TMP_DIR}/.lock", os.O_CREAT | os.O_EXCL | os.O_WRONLY)
            os.close(lock)
        except:
            print(f"Error: Can't create temporary dir or .lock file at {TMP_DIR}")
            sys.exit(1)

    # Create arguments
    parser = argparse.ArgumentParser()
    parser.add_argument('--inventory', '-i', help="Path to the inventory file. Default is '/etc/ansible/hosts'.")
    parser.add_argument('--zabbix-server', default=ZABBIX_SERVER, help="The Zabbix server FQDN or IP address.")
    parser.add_argument('--zabbix-host', default=ZABBIX_HOST, help="The Zabbix host to send logs.")
    parser.add_argument('--limit', '-l', default='all', help="Limit the scope of the operation (e.g., 'host1' or 'group1'). Default is 'all'.")
    parser.add_argument('--upgrade', '-u', action='store_const', const='yes', default='no', help="Set to 'yes' to enable upgrade mode (default is 'no').")
    parser.add_argument('--ignore-sshcheck', '-k', action='store_true', help="Ignore SSH check (useful for testing without valid SSH keys).")
    parser.add_argument('--become', '-b', action='store_const', const='yes', default='no', help="Run commands with elevated privileges (default is 'no').")
    parser.add_argument('--verbose', '-v', action='count', default=0, help="Increase verbosity. Use -v for basic verbosity, -vv for more detailed.")
    parser.add_argument('--user', default=USER_LOGIN, help="Username for authentication.")
    parser.add_argument('--ssh-key', '-K', dest='sshkey', default=SSH_KEY, help="Path to the SSH private key for authentication.")
    parser.add_argument('--forks', '-f', help="Number of parallel forks to use during the operation (default is 5).")
    parser.add_argument('--package-manager', default=PKG_MGR, help="Package manager to use (e.g., apt, yum, dnf).")
    parser.add_argument('--lock-packages', '-L', help="Lock specific packages to prevent updates or changes.")
    parser.add_argument('--unlock-packages', '-U', help="Unlock specific packages for updates or changes.")    
    parser.add_argument('--timeout', '-t', help="Ansible SSH timeout (default is 10).")
    #parser.add_argument('--dry-run', action='store_true') # Not implemented yet

    try:
        args = parser.parse_args()
        
        # Set verbose var
        global verbose
        verbose = args.verbose
        printverbose("Contribute to https://github.com/zingaya/zbx_linux_security_compliance")
        
        # Change SSH host key checking. Same as 'ssh -o StrictHostKeyChecking=no'
        os.environ['ANSIBLE_HOST_KEY_CHECKING'] = 'false' if args.ignore_sshcheck else 'true'

        # Set user login
        os.environ['ANSIBLE_REMOTE_USER'] = args.user
        
        # No color output for Ansible. This affects some loggin filtering later in this script.
        os.environ['ANSIBLE_NOCOLOR'] = '1'

        # SSH key path
        args.sshkey = args.sshkey.replace("~", os.environ['HOME'])
        if os.path.isfile(args.sshkey):
            os.environ['ANSIBLE_PRIVATE_KEY_FILE'] = args.sshkey
        else:
            raise Exception(f"SSH key {args.sshkey} file not found")
          
        # Set and validate Ansible forks
        forks = (
            args.forks
            if args.forks is not None
            else ANSIBLE_FORKS
            if "ANSIBLE_FORKS" in globals()
            else 5  # Default value
        )
        os.environ['ANSIBLE_FORKS'] = str(forks)
        if not is_positive_int(os.environ['ANSIBLE_FORKS']):
            raise Exception("ANSIBLE_FORKS must be a positive integer")

        # Set and validate Ansible timeout
        timeout = (
            args.timeout
            if args.timeout is not None
            else ANSIBLE_TIMEOUT
            if "ANSIBLE_TIMEOUT" in globals()
            else 10  # Default value
        )
        os.environ['ANSIBLE_TIMEOUT'] = str(timeout)
        if not is_positive_int(os.environ['ANSIBLE_TIMEOUT']):
            raise Exception("ANSIBLE_TIMEOUT must be a positive integer")
        
        # Values should be a list, try to correct if possible.
        if not isinstance(args.package_manager, (tuple, list)):
            args.package_manager = args.package_manager.replace(',', ' ').strip().split()            
        if not isinstance(args.zabbix_server, (tuple, list)):
            args.zabbix_server = args.zabbix_server.replace(',', ' ').strip().split()
            
        # Validate Zabbix hosts
        for host in args.zabbix_server:
            if not is_valid_host(host):
                raise Exception(f"{host} is not a valid hostname, FQDN, or hostname:port")
            
        # Create Ansible hosts file from Zabbix
        if "ZABBIX_API" in globals() and "API_TOKEN" in globals():
            if is_valid_url(ZABBIX_API):
                args.inventory = f"{TMP_DIR}/hosts.yaml"
                handle = create_ansible_inventory(args.inventory)
            else:
                raise Exception(f"ZABBIX_API is not a valid URL")
            # End execution if failed to retrieve data
            if handle:
                raise Exception(handle)

            print("Created Ansible inventory from Zabbix API: " + args.inventory)
            if args.verbose:
                with open(args.inventory) as f:
                    file_contents = f.read()
                    print("Ansible inventory contents:\n" + file_contents)
        else:
            # Set and validate inventory file
            args.inventory = (
                args.inventory
                if args.inventory is not None
                else INVENTORY_PATH
                if "INVENTORY_PATH" in globals()
                else '/etc/ansible/hosts'  # Default value
            )
            if not os.path.isfile(args.inventory): raise Exception("Inventory file not found")

        # Prepare Zabbix connection
        sender = Sender(clusters=[args.zabbix_server])

        # Initialize var for later use
        combined_output = ""
        
        # Read string of packages and transform into a list
        packages_split_lock = args.lock_packages.split() if args.lock_packages else []
        packages_split_unlock = args.unlock_packages.split() if args.unlock_packages else []

        # Gather package manager info
        print("Gatthering hosts data...")
        r1 = ansible_runner.run(
            module='setup',
            module_args='gather_subset=system',
            host_pattern=args.limit,
            inventory=args.inventory,
            private_data_dir=TMP_DIR,
            streamer='file',
            quiet=(args.verbose == 0),
            verbosity=max(0, args.verbose - 1)
        )
        
        host_list = {}
        for event in r1.events:
            match = re.match(r'^runner_on_', event.get("event"))
            if match:
                host = event['event_data']['host']
                if event.get("event") == "runner_on_ok":
                    facts = event['event_data']['res'].get('ansible_facts', {})
                    host_list[host] = {
                        "pkg_mgr": facts.get('ansible_pkg_mgr'),
                        "distribution": facts.get('ansible_distribution'),
                        "distribution_version": facts.get('ansible_distribution_version'),
                        "kernel": facts.get('ansible_kernel'),
                        "selinux": facts.get('ansible_selinux')
                    }
                elif event.get("event") == "runner_on_unreachable":
                    msg_json = re.search(r'({.*)', event.get("stdout", "{}").strip().replace("\r\n", ""))
                    host_list[host] = {"error": event.get("event"), "msg": json.loads(msg_json.group(1))}

        pkg_mgr_list = defaultdict(list)

        for host, data in host_list.items():
            pkg_mgr = data.get("pkg_mgr")
            if pkg_mgr:
                pkg_mgr_list[pkg_mgr].append(host)

        printverbose("Inventory result: " + json.dumps(host_list))
        printverbose("Package manager grouping: " + json.dumps(dict(pkg_mgr_list)))        

        # Execute Ansible playbooks for each package manager
        runners = []

        # Do nothing and jump directly to send report to zabbix
        if not pkg_mgr_list:
            print('Nothing to do')
        else:
            print("Running Ansible playbook(s)...")
            for pkgmgr in pkg_mgr_list:
                # Check if pkg_mgr is in "allowed"
                if pkgmgr in args.package_manager:
                    # Build playbook YAML per pkg_mgr
                    build_playbook(args, packages_split_lock, packages_split_unlock, pkgmgr)

                    limit_host = ','.join(pkg_mgr_list[pkgmgr])

                    # Execute Ansible (async)
                    ident, r2 = ansible_runner.run_async(
                        private_data_dir=TMP_DIR,
                        playbook=f"{TMP_DIR}/{pkgmgr}_playbook.yaml",
                        limit=limit_host,
                        inventory=args.inventory,
                        streamer='file',
                        quiet=(args.verbose == 0),
                        verbosity=max(0, args.verbose - 1)
                    )
                    printverbose(f"Started playbook for {pkgmgr} on: {limit_host}")
                    runners.append((pkgmgr, r2))

            # Wait for all to finish by polling their status
            while runners:
                for pkgmgr, r2 in list(runners):  # Copy the list to prevent modification during iteration
                    if r2.status == 'successful' or r2.status == 'failed' or r2.status == 'canceled':
                        printverbose(f"{pkgmgr} finished with status: {r2.status}, rc={r2.rc}")
                        runners.remove((pkgmgr, r2))
                time.sleep(1)  # Poll every second

            print("Ansible playbook(s) finished. Sending data to Zabbix...")

            # Build JSON for each host, as individual items, to be sent to Zabbix
            items = []
            process_json_files(TMP_DIR, items, combined_output, host_list)
            # If items exist, send them to Zabbix
            if items:            
                # Send data to Zabbix
                response = sender.send(items)
                combined_output += f"All values sent to Zabbix. Response: {response}"

                printverbose("Data sent to Zabbix: " + str(items))
                printverbose(combined_output)

        # Gatther hosts failed to get facts, stdout & stderr for each Ansible run
        combined_output += "Ansible failed hosts:\n"

        for host, err_detail in host_list.items():
            if 'error' in err_detail:
                combined_output += f"{host}: {err_detail['error']}\n"

        combined_output += "Ansible log (filtered failed only):\n"
        output_files = Path(TMP_DIR + "/artifacts")
        for output_file in output_files.rglob('stdout'):
            with open(output_file) as f:
                filtered_lines = [line.rstrip('\n') for line in f if line.startswith(('[WARNING]', "PLAY [", "TASK [", "failed:"))]
                if filtered_lines:
                    combined_output += "\n".join(filtered_lines) + "\n"

            stderr_file = output_file.with_name('stderr')
            with open(stderr_file) as f:
                stderr_lines = [line.rstrip('\n') for line in f if line.strip()]
                if stderr_lines:
                    combined_output += "Stderr:\n"
                    combined_output += "\n".join(stderr_lines) + "\n"
                    
        # Output execution time
        end = time.time()
        elapsed = end - start

        hours, rem = divmod(elapsed, 3600)
        minutes, seconds = divmod(rem, 60)

        print(f"Total execution time: {int(hours):02}:{int(minutes):02}:{seconds:06.3f}")
        combined_output += f"Total execution time: {int(hours):02}:{int(minutes):02}:{seconds:06.3f}"
    
        # Send log to Zabbix
        try:
            response = sender.send_value(args.zabbix_host, "ansible.result", combined_output)
            if json.loads(str(response)).get('failed') == 1:
                print(f"Couldn't send logs to host '{args.zabbix_host}'. Check ZABBIX_HOST var and if the host exists on Zabbix, and have the template.")
            
            printverbose(f"Response from Zabbix (log host): {response}")
            print("All done!")
        except Exception as e:
            print(f"Error: {e}")
         
    except Exception as e:
        msg = str(e)
        if verbose:
            import traceback
            traceback.print_exc()
        else:
            if "Couldn't connect to all of cluster nodes" in msg:
                # For better understanding to "what" is not connecting
                msg = msg.replace("cluster", "Zabbix cluster")
            print(f"Error: {msg}")
    
    finally:
        # Clean up temporary files
        shutil.rmtree(TMP_DIR)

if __name__ == "__main__":
    main()